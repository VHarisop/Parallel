\documentclass[11pt,a4paper]{article}
\usepackage{xltxtra} 
\usepackage{xgreek} 
\usepackage{amsmath}


\setmainfont[
    UprightFont = Kerkis,
    ItalicFont = KerkisItalics,
    SlantedFont = KerkisItalics,
    BoldFont = Kerkisb,
    BoldItalicFont = Kerkisbi,
    BoldSlantedFont = Kerkisbi,
    SmallCapsFont = KerkisSmallCaps]
    {Kerkis}
\setmonofont[Mapping=tex-text]{Consolas}
\raggedbottom
\everymath{\displaystyle}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}


\begin{document}

\begin{titlepage}
\centering

% Upper part of the page
%\includegraphics{Pyrforos.png}\\[1cm]    

\textsc{\LARGE Σχολη \\ Ηλεκτρολογων Μηχανικων \\[-3pt] και \\[6pt] Μηχανικων Υπολογιστων}\\[1.5cm]
{\Large Παράλληλα Συστήματα Επεξεργασίας}\\[0.5cm]

% Title
\HRule \\[0.5cm]
{\huge \bfseries Ενδιάμεση Αναφορά}\\[0.2cm]
\HRule \\[1.5cm]

% Authors
\begin{minipage}{0.4\textwidth}
\large
Κουτσούκος Δημήτριος \\
(ΑΜ: 03110078) \\
Χαρισόπουλος Βασίλειος \\
(ΑΜ: 03110046)
\end{minipage}

\vfill

{\large \today}
\end{titlepage}

\clearpage
\clearpage
\newpage
\section{Υλοποίηση MPI}
\subsection{Μέθοδος Jacobi}
Η επαναληπτική μέθοδος Jacobi χρησιμοποιεί τις τιμές των 4 γειτονικών σημείων του πλέγματος, οι οποίες αφορούν την προηγούμενη χρονική στιγμή του υπολογισμού. Ο τύπος της είναι
\[ u_{x,y}^{t+1} = \frac{u_{x-1,y}^t + u_{x,y-1}^t + u_{x+1, y}^t + u_{x, y+1}^t}{4} \]
Επομένως στον υπολογισμό των στοιχείων για την χρονική στιγμή $t+1$ για τυχαίο σημείο του πλέγματος δεν υπάρχουν εξαρτήσεις από άλλους υπολογισμούς που μπορεί να γίνονται ταυτόχρονα για άλλο σημείο.
\subsubsection{Διαμοιρασμός πίνακα στο MPI}
Μπορούμε να διαμοιράσουμε είτε κατά στήλες/γραμμές (1D partition), είτε να χωρίσουμε τον πίνακα σε block (2D partition). 
Για λόγους ευκολίας και περιορισμού της επικοινωνίας έχουμε επιλέξει τον πρώτο τύπο διαμοιρασμού. \\
Οι συναρτήσεις του MPI που χρησιμοποιούμε για το διαμοιρασμό των στοιχείων του πίνακα είναι οι \texttt{MPI\_Send, MPI\_Recv}.
\subsubsection{Ανταλλαγή στοιχείων μεταξύ επεξεργαστών}
Εφόσον ακολουθήσουμε διαμέριση κατά στήλες, οι επεξεργαστές πρέπει να ανταλλάσσουν είναι τα γειτονικά τους, 
δηλαδή για το block που περιλαμβάνει τις στήλες $i...i+k$, πρέπει να αποστείλει τις στήλες $i, i+k$ μέσω της \texttt{MPI\_Send}
και να ανακτήσει τις στήλες $i-1, i+k+1$ μέσω της \texttt{MPI\_Recv}. Γενικά σε κάθε τύπο διαμέρισης, 2 επεξεργαστές ανταλλάσσουν στοιχεία μονάχα αν "γειτνιάζουν" στο partition του πίνακα που ακολουθείται. \\ \\
Η ανταλλαγή δεδομένων μπορεί να γίνεται στην αρχή της φάσης των υπολογισμών για κάθε χρονική στιγμή $t_i$. Εναλλακτικά ο κάθε επεξεργαστής μπορεί να υπολογίζει τα στοιχεία που είναι εφικτό να υπολογίσει χωρίς δεδομένα που ανήκουν σε άλλο επεξεργαστή και η ανταλλαγή δεδομένων να γίνεται μετά από αυτή τη διαδικασία. \\
Τα δεδομένα που ανταλλάσσονται, όταν στέλνονται μέσω της \texttt{MPI\_Send} αποθηκεύοναι στον MPI Buffer, απ'όπου ανακτώνται όταν καλείται η \texttt{MPI\_Recv}.

\subsubsection{Έλεγχος Σύγκλισης}
Κάθε διεργασία κάνει έλεγχο σύγκλισης στα δεδομένα που έχει υπολογίσει τοπικά μέσω της \texttt{converge()}. Η converge επιστρέφει 
\begin{itemize}
	\item 0 εάν συναντήσει αποκλίνουσες τιμές (άρα αποτυχία σύγκλισης)
	\item 1 εάν διαπιστώσει σύγκλιση
\end{itemize}
Επομένως, έχοντας χωρίσει τον πίνακα $A$ σε κομμάτια $A_i, i \in \text{\#Processors} $, συνολική σύγκλιση συνεπάγεται να έχουν συγκλίνει όλα τα κομμάτια, άρα ουσιαστικά $ \min\{\text{\texttt{converge}}(A_i) \} = 1$ (το $\min()$ αντιστοιχεί στο λογικό AND για συναρτήσεις σαν την \texttt{converge()}). Έτσι, εύκολα διαπιστώνουμε ότι μπορούμε να ελέγξουμε για συνολική σύγκλιση μέσω της \texttt{MPI\_Reduce}, χρησιμοποιώντας για τελεστή τον \texttt{MPI\_MIN}.

\subsection{Μέθοδος Red-Black SOR}
Η μέθοδος Red-Black SOR έχει 2 διακριτές φάσεις υπολογισμού. Η πρώτη είναι η ανανέωση των "red" σημείων του πλέγματος, και δίνεται από τον τύπο
\[ u_{x,y}^{t+1} = u_{x,y}^t + \omega \frac{u_{x-1,y}^t + u_{x,y-1}^t + u_{x+1, y}^t + u_{x, y+1}^t - 4u_{x,y}^t}{4}, (x+y) \%  \]

\end{document}

